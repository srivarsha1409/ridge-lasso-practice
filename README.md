ğŸ“Š RIDGE,LASSO & POLYNOMIAL ANALYSIS:

ğŸ“OVERVIEW:

This project applies Ridge, Lasso, and Polynomial Regression on various datasets to handle multicollinearity, perform feature selection, and model non-linear relationships. Models are evaluated using RÂ² and RMSE.

âœ¨ KEY FEATURES:

ğŸŸ¦ Ridge Regression: Handles correlated features, finds optimal alpha via cross-validation.

ğŸŸª Lasso Regression: Performs feature selection by shrinking irrelevant coefficients to zero.

ğŸŸ© Polynomial Regression: Models non-linear relationships and compares with linear fit.

ğŸ“ Evaluation: Coefficients, intercept, RÂ², and RMSE reported for all models.




âš™ï¸ REQUIREMENTS:

Python >= 3.8

Libraries: numpy, pandas, matplotlib, scikit-learn, jupyter

Install via:

pip install numpy pandas matplotlib scikit-learn jupyter





âœ¨ SCRIPTS & FEATURES

TASK 1:ğŸŸ¦ Ridge Regression (2 correlated features)

Dataset: ridge_correlated_150.csv

Finds best alpha via cross-validation.

Outputs coefficients, intercept, RÂ², and RMSE.



TASK 2:ğŸŸ¦ Ridge Regression (10 features)

Dataset: ridge_10feat_150.csv

Handles multiple features, finds best alpha.

Evaluates model performance with RÂ² and RMSE.



TASK 3:ğŸŸª Lasso Regression (sparse features)

Dataset: lasso_sparse_150.csv

Performs automatic feature selection.

Reports selected features, RÂ², and RMSE.



TASK 4:ğŸŸª Lasso Regression (grouped features)

Dataset: lasso_groups_150.csv

Standardizes features before Lasso.

Reports coefficients on original scale, intercept, RÂ², and RMSE.




TASK 5:ğŸŸ© Polynomial Regression (quadratic)

Dataset: poly_quadratic_150.csv

Compares linear vs. quadratic fit.

Reports coefficients, intercept, RÂ², RMSE, and predicts new values.


âœï¸AUTHOR

SRI VARSHA P
